# streamlit_app.py

import os
import sys
import logging
import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import DocArrayInMemorySearch
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.docstore.document import Document
from docx import Document as DocxDocument

# ---------------------------------------
# 1. Loglama AyarlarÄ±
# ---------------------------------------
if not os.path.exists("logs"):
    os.makedirs("logs")

logging.basicConfig(
    filename="logs/error.log",
    level=logging.ERROR,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# ---------------------------------------
# 2. Streamlit Sayfa YapÄ±sÄ± - SadeleÅŸtirilmiÅŸ
# ---------------------------------------
st.set_page_config(page_title="Villa Villa Yapay Zeka", layout="wide")

# BaÅŸlÄ±k bÃ¶lÃ¼mÃ¼
col1, col2 = st.columns([1, 5])
with col1:
    try:
        st.image("assets/villa_villa_logo.jpg", width=100)
    except Exception:
        pass
with col2:
    st.title("Villa Villa Yapay Zeka ile Sohbet")

st.markdown("---")

# ---------------------------------------
# 3. OpenAI API AnahtarÄ± YÃ¶netimi (Sadece Secrets)
# ---------------------------------------
def set_openai_api_key():
    # Secrets'dan API anahtarÄ±nÄ± al
    openai_api_key = st.secrets.get("openai", {}).get("api_key", None)
    if openai_api_key:
        os.environ["OPENAI_API_KEY"] = openai_api_key
        return True
    
    # API anahtarÄ± bulunamadÄ±
    st.error("API anahtarÄ± bulunamadÄ±. LÃ¼tfen Streamlit Secrets ayarlarÄ±nÄ± kontrol edin.")
    return False

# ---------------------------------------
# 4. Belgeleri YÃ¼kleme Fonksiyonu (.docx)
# ---------------------------------------
def load_documents_from_folder(folder_path="data"):
    documents = []
    if not os.path.exists(folder_path):
        st.error(f"Belge klasÃ¶rÃ¼ bulunamadÄ±: {folder_path}")
        return documents

    for filename in os.listdir(folder_path):
        if filename.endswith(".docx"):
            full_path = os.path.join(folder_path, filename)
            try:
                docx = DocxDocument(full_path)
                text = "\n".join([p.text for p in docx.paragraphs if p.text.strip() != ""])
                documents.append(Document(page_content=text, metadata={"source": filename}))
                print(f"Belge yÃ¼klendi: {filename}, Ä°Ã§erik uzunluÄŸu: {len(text)} karakter")
            except Exception as e:
                logging.error(f"{filename} yÃ¼klenirken hata: {str(e)}")
    
    return documents

# ---------------------------------------
# 5. VektÃ¶r VeritabanÄ± OluÅŸturma
# ---------------------------------------
def create_vector_db(documents):
    try:
        # Belgeleri parÃ§alara bÃ¶l
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1500, 
            chunk_overlap=200,
            separators=["\n\n", "\n", ". ", " ", ""],
            length_function=len
        )
        chunks = splitter.split_documents(documents)
        print(f"Belgeler {len(chunks)} parÃ§aya bÃ¶lÃ¼ndÃ¼")
        
        # Embeddings oluÅŸtur
        try:
            # API anahtarÄ±nÄ± kontrol et
            api_key = os.environ.get("OPENAI_API_KEY", "")
            if not api_key:
                print("API anahtarÄ± bulunamadÄ±!")
                return None
                
            embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small"
            )
            print("OpenAIEmbeddings baÅŸarÄ±yla oluÅŸturuldu")
            
            # VektÃ¶r veritabanÄ± oluÅŸtur
            vector_db = DocArrayInMemorySearch.from_documents(
                documents=chunks,
                embedding=embeddings,
            )
            print("VektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu")
            return vector_db
            
        except Exception as e:
            import traceback
            error_msg = f"Embedding hatasÄ±: {str(e)}"
            print(error_msg)
            print(f"Hata detayÄ±: {traceback.format_exc()}")
            return None
            
    except Exception as e:
        logging.error(f"VektÃ¶r veritabanÄ± hatasÄ±: {str(e)}")
        return None

# ---------------------------------------
# 6. Ã–zel Prompt Åablonu
# ---------------------------------------
def create_qa_prompt():
    template = """
    Sen Villa Villa ÅŸirketinin finans ve operasyon asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki belgelerden alÄ±nan bilgilere dayanarak sorularÄ± yanÄ±tla:

    Belgelerden Bilgiler:
    {context}

    Sohbet GeÃ§miÅŸi:
    {chat_history}

    Soru:
    {question}

    YanÄ±tÄ±n sadece belgelerden aldÄ±ÄŸÄ±n bilgilere dayanmalÄ±. EÄŸer belgede yanÄ±t yoksa, "Bu konuda mevcut belgelerimde bilgi bulamadÄ±m" ÅŸeklinde belirt. Tahmin yÃ¼rÃ¼tme, bilmediÄŸin konularda uydurma.

    YanÄ±t:
    """
    return PromptTemplate(input_variables=["context", "chat_history", "question"], template=template)

# ---------------------------------------
# 7. Chat Zinciri Kurulumu
# ---------------------------------------
def create_chat_chain(vector_db):
    try:
        llm = ChatOpenAI(
            temperature=0.2,
            model_name="gpt-4-turbo"
        )
        
        retriever = vector_db.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 8, "fetch_k": 15}
        )
        qa_prompt = create_qa_prompt()
        
        chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=retriever,
            return_source_documents=True,
            combine_docs_chain_kwargs={"prompt": qa_prompt}
        )
        return chain
    except Exception as e:
        logging.error(f"Chat zinciri hatasÄ±: {str(e)}")
        return None

# ---------------------------------------
# 8. Ana Uygulama
# ---------------------------------------
def main():
    # Global API anahtarÄ± ayarla
    if not set_openai_api_key():
        st.stop()

    # Session state deÄŸiÅŸkenleri
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    if "documents" not in st.session_state or "vector_db" not in st.session_state or "chat_chain" not in st.session_state:
        # Belgeleri yÃ¼kle
        with st.spinner("Belgeler yÃ¼kleniyor..."):
            documents = load_documents_from_folder("data")
            if not documents:
                st.error("HiÃ§ belge bulunamadÄ±! LÃ¼tfen 'data' klasÃ¶rÃ¼ne .docx belgelerinizi ekleyin.")
                st.stop()
            
            st.session_state.documents = documents
        
        # VektÃ¶r veritabanÄ± oluÅŸtur
        with st.spinner("VektÃ¶r veritabanÄ± oluÅŸturuluyor..."):
            vector_db = create_vector_db(documents)
            if not vector_db:
                st.error("VektÃ¶r veritabanÄ± oluÅŸturulamadÄ±!")
                st.stop()
            
            st.session_state.vector_db = vector_db
        
        # Chat zinciri oluÅŸtur
        with st.spinner("Sohbet sistemi hazÄ±rlanÄ±yor..."):
            chat_chain = create_chat_chain(vector_db)
            if not chat_chain:
                st.error("Sohbet sistemi oluÅŸturulamadÄ±!")
                st.stop()
            
            st.session_state.chat_chain = chat_chain
    
    # Sohbet geÃ§miÅŸini gÃ¶rÃ¼ntÃ¼le - Merkezi konumlandÄ±rma
    chat_container = st.container()
    with chat_container:
        for i in range(0, len(st.session_state.chat_history), 2):
            if i < len(st.session_state.chat_history):
                with st.chat_message("user"):
                    st.markdown(st.session_state.chat_history[i][1])
            
            if i+1 < len(st.session_state.chat_history):
                with st.chat_message("assistant"):
                    st.markdown(st.session_state.chat_history[i+1][1])
    
    # KullanÄ±cÄ± giriÅŸi
    user_input = st.chat_input("Sorunuzu yazÄ±nÄ±z...")
    
    # Temizleme butonlarÄ± - Chat altÄ±nda
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ§¹ Sohbeti Temizle", use_container_width=True):
            st.session_state.chat_history = []
            st.rerun()
    with col2:
        if st.button("ğŸ”„ Ã–nbelleÄŸi Temizle", use_container_width=True):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()
    
    if user_input:
        with st.chat_message("user"):
            st.markdown(user_input)
        
        st.session_state.chat_history.append(("user", user_input))
        
        try:
            # Sohbet geÃ§miÅŸini uygun formata dÃ¶nÃ¼ÅŸtÃ¼r
            chat_formatted = []
            for i in range(0, len(st.session_state.chat_history)-1, 2):
                if i+1 < len(st.session_state.chat_history):
                    chat_formatted.append((st.session_state.chat_history[i][1], 
                                        st.session_state.chat_history[i+1][1]))
            
            # YanÄ±t oluÅŸtur
            with st.spinner("DÃ¼ÅŸÃ¼nÃ¼yor..."):
                response = st.session_state.chat_chain({
                    "question": user_input,
                    "chat_history": chat_formatted
                })
            
            # YanÄ±tÄ± gÃ¶ster
            with st.chat_message("assistant"):
                st.markdown(response["answer"])
            
            # YanÄ±tÄ± geÃ§miÅŸe ekle
            st.session_state.chat_history.append(("assistant", response["answer"]))
            
        except Exception as e:
            logging.error(f"YanÄ±t hatasÄ±: {str(e)}")
            with st.chat_message("assistant"):
                st.error("ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸturulurken bir hata oluÅŸtu.")
            st.session_state.chat_history.append(("assistant", "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu."))

# ---------------------------------------
# 9. Uygulama BaÅŸlatÄ±lÄ±yor
# ---------------------------------------
if __name__ == "__main__":
    main()