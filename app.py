import os
import sys
import tempfile
import logging
import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import DocArrayInMemorySearch
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.docstore.document import Document
from docx import Document as DocxDocument

# ---------------------------------------
# 1. Loglama AyarlarÄ±
# ---------------------------------------
if not os.path.exists("logs"):
    os.makedirs("logs")

logging.basicConfig(
    filename="logs/error.log",
    level=logging.ERROR,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# ---------------------------------------
# 2. Streamlit Sayfa YapÄ±sÄ±
# ---------------------------------------
st.set_page_config(page_title="Villa Villa Yapay Zeka", layout="centered")

col1, col2 = st.columns([1, 3])
with col1:
    try:
        st.image("assets/villa_villa_logo.jpg", width=100)
    except Exception:
        pass
with col2:
    st.title("Villa Villa Yapay Zeka ile Sohbet")

st.markdown("---")

# ---------------------------------------
# 3. OpenAI API AnahtarÄ± YÃ¶netimi (Sadece Secrets)
# ---------------------------------------
def set_openai_api_key():
    # Secrets'dan API anahtarÄ±nÄ± al
    openai_api_key = st.secrets.get("openai", {}).get("api_key", None)
    if openai_api_key:
        os.environ["OPENAI_API_KEY"] = openai_api_key
        return True
    
    # API anahtarÄ± bulunamadÄ±
    st.error("API anahtarÄ± bulunamadÄ±. LÃ¼tfen Streamlit Secrets ayarlarÄ±nÄ± kontrol edin.")
    st.info("Secrets dosyasÄ±nda ÅŸu formatta API anahtarÄ±nÄ±zÄ± tanÄ±mlayÄ±n: [openai] api_key = 'your-api-key'")
    return False

# ---------------------------------------
# 4. Belgeleri YÃ¼kleme Fonksiyonu (.docx)
# ---------------------------------------
def load_documents_from_folder(folder_path="data"):
    documents = []
    if not os.path.exists(folder_path):
        st.warning(f"Belge klasÃ¶rÃ¼ bulunamadÄ±: {folder_path}. Ã–rnek veri kullanÄ±lacak.")
        # Ã–rnek belgeler oluÅŸtur
        return create_test_documents()

    for filename in os.listdir(folder_path):
        if filename.endswith(".docx"):
            full_path = os.path.join(folder_path, filename)
            try:
                docx = DocxDocument(full_path)
                text = "\n".join([p.text for p in docx.paragraphs if p.text.strip() != ""])
                documents.append(Document(page_content=text, metadata={"source": filename}))
                print(f"Belge yÃ¼klendi: {filename}, Ä°Ã§erik uzunluÄŸu: {len(text)} karakter")
            except Exception as e:
                logging.error(f"{filename} yÃ¼klenirken hata: {str(e)}")
                st.error(f"{filename} yÃ¼klenirken hata: {str(e)}")
    
    if not documents:
        st.warning("Belge bulunamadÄ±. Ã–rnek veri kullanÄ±lacak.")
        return create_test_documents()
    
    return documents

# ---------------------------------------
# 5. Test Belgeleri OluÅŸturma
# ---------------------------------------
def create_test_documents():
    documents = []
    
    yapilan_isler_content = """
    Villa Villa Organizasyon - YapÄ±lan Ä°ÅŸler
    
    Tarih: 15 Nisan 2025
    MÃ¼ÅŸteri: ABC Åirketi
    Etkinlik TÃ¼rÃ¼: Kurumsal YÄ±l DÃ¶nÃ¼mÃ¼
    KiÅŸi SayÄ±sÄ±: 150
    MenÃ¼: Ana yemek, 5 Ã§eÅŸit meze, 2 Ã§eÅŸit tatlÄ±
    Toplam Maliyet: 75,000 TL
    
    Tarih: 10 Nisan 2025
    MÃ¼ÅŸteri: XYZ Ltd.
    Etkinlik TÃ¼rÃ¼: ÃœrÃ¼n LansmanÄ±
    KiÅŸi SayÄ±sÄ±: 80
    MenÃ¼: Kokteyl, 10 Ã§eÅŸit kanape
    Toplam Maliyet: 40,000 TL
    """
    
    genel_gider_content = """
    Villa Villa Organizasyon - Genel Giderler
    
    Nisan 2025:
    Kira: 15,000 TL
    Elektrik: 2,500 TL
    Su: 800 TL
    Ä°nternet: 600 TL
    Personel MaaÅŸlarÄ±: 45,000 TL
    Toplam: 63,900 TL
    
    Mart 2025:
    Kira: 15,000 TL
    Elektrik: 2,800 TL
    Su: 750 TL
    Ä°nternet: 600 TL
    Personel MaaÅŸlarÄ±: 45,000 TL
    Toplam: 64,150 TL
    """
    
    doc1 = Document(page_content=yapilan_isler_content, metadata={"source": "yapilan_isler.docx"})
    doc2 = Document(page_content=genel_gider_content, metadata={"source": "genel_gider.docx"})
    
    documents.extend([doc1, doc2])
    return documents

# ---------------------------------------
# 6. VektÃ¶r VeritabanÄ± (DocArrayInMemorySearch)
# ---------------------------------------
def create_vector_db(documents):
    try:
        # Belgeleri parÃ§alara bÃ¶l - Daha bÃ¼yÃ¼k chunk boyutu ve daha fazla overlap
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1500,  # 800'den 1500'e artÄ±rÄ±ldÄ±
            chunk_overlap=200,  # 150'den 200'e artÄ±rÄ±ldÄ±
            separators=["\n\n", "\n", ". ", " ", ""],
            length_function=len
        )
        chunks = splitter.split_documents(documents)
        st.info(f"Belgeler {len(chunks)} parÃ§aya bÃ¶lÃ¼ndÃ¼")
        
        # Debugging - Her chunk'Ä±n ilk 100 karakterini gÃ¶ster
        print(f"Ä°lk 3 chunk Ã¶rneÄŸi:")
        for i, chunk in enumerate(chunks[:3]):
            print(f"Chunk {i+1}: {chunk.page_content[:100]}...")
        
        # Embeddings oluÅŸtur
        try:
            # API anahtarÄ±nÄ± kontrol et
            api_key = os.environ.get("OPENAI_API_KEY", "")
            if not api_key:
                st.error("API anahtarÄ± bulunamadÄ±!")
                return None
                
            # API anahtarÄ±nÄ±n gÃ¼venli kontrolÃ¼
            print(f"API anahtarÄ± Secrets'dan yÃ¼klendi ve kullanÄ±ma hazÄ±r")
            
            embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small"  # GÃ¼ncel embedding modeli
            )
            print("OpenAIEmbeddings baÅŸarÄ±yla oluÅŸturuldu")
            
            # DocArrayInMemorySearch vektÃ¶r veritabanÄ± oluÅŸtur
            vector_db = DocArrayInMemorySearch.from_documents(
                documents=chunks,
                embedding=embeddings,
            )
            print("DocArrayInMemorySearch vektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu")
            return vector_db
            
        except Exception as e:
            import traceback
            error_msg = f"Embedding hatasÄ±: {str(e)}"
            print(error_msg)
            print(f"Hata detayÄ±: {traceback.format_exc()}")
            st.error(f"Embedding oluÅŸturulurken hata: {str(e)}")
            return None
            
    except Exception as e:
        logging.error(f"VektÃ¶r veritabanÄ± hatasÄ±: {str(e)}")
        st.error(f"VektÃ¶r veritabanÄ± oluÅŸturulurken hata: {str(e)}")
        return None

# ---------------------------------------
# 7. Ã–zel Prompt Åablonu
# ---------------------------------------
def create_qa_prompt():
    template = """
    Sen Villa Villa ÅŸirketinin finans ve operasyon asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki belgelerden alÄ±nan bilgilere dayanarak sorularÄ± yanÄ±tla:

    Belgelerden Bilgiler:
    {context}

    Sohbet GeÃ§miÅŸi:
    {chat_history}

    Soru:
    {question}

    Notlar:
    - YanÄ±tÄ±nÄ± verirken belgelerdeki bilgileri kullan.
    - Bilgi ÅŸu dosyalarda bulunabilir: gelen_faturalar.docx, genel_gider.docx, personel_giderleri.docx ve yapilan_isler.docx
    - EÄŸer belgede yanÄ±t yoksa aÃ§Ä±kÃ§a belirt.
    - SayÄ±sal hesaplamalar yapabilir, toplam giderleri hesaplayabilirsin.
    - DetaylÄ± ve kapsamlÄ± yanÄ±t ver.

    YanÄ±t:
    """
    return PromptTemplate(input_variables=["context", "chat_history", "question"], template=template)

# ---------------------------------------
# 8. Chat Zinciri Kurulumu
# ---------------------------------------
def create_chat_chain(vector_db):
    try:
        llm = ChatOpenAI(
            temperature=0.2,
            model_name="gpt-4-turbo"  # GÃ¼ncel model adÄ±
        )
        
        # MMR arama algoritmasÄ± ve daha fazla belge getirme
        retriever = vector_db.as_retriever(
            search_type="mmr",  # Maximum Marginal Relevance - benzer ancak farklÄ± belgeler getirir
            search_kwargs={"k": 8, "fetch_k": 15}  # Daha fazla belge getir
        )
        qa_prompt = create_qa_prompt()
        
        chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=retriever,
            return_source_documents=True,
            combine_docs_chain_kwargs={"prompt": qa_prompt}
        )
        return chain
    except Exception as e:
        logging.error(f"Chat zinciri hatasÄ±: {str(e)}")
        st.error(f"Sohbet sistemi oluÅŸturulamadÄ±: {str(e)}")
        return None

# ---------------------------------------
# 9. Ana Uygulama
# ---------------------------------------
def main():
    # Streamlit Ã¶nbelleÄŸini temizle
    # Bu, her uygulama baÅŸlangÄ±cÄ±nda Ã¶nbelleÄŸi temizler
    try:
        st.cache_data.clear()
    except:
        pass
    try:
        st.cache_resource.clear()
    except:
        pass
    
    # Global API anahtarÄ± ayarla (sadece Secrets'dan)
    if not set_openai_api_key():
        st.stop()

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
        
    # Sidebar - Ayarlar
    with st.sidebar:
        st.header("Ayarlar")
        use_test_data = st.checkbox("Test verileri kullan", value=False)  # VarsayÄ±lan olarak gerÃ§ek verileri kullan
        
        # Temizle butonu
        if st.button("Sohbeti Temizle"):
            st.session_state.chat_history = []
            st.rerun()
        
        # Ã–nbelleÄŸi temizle butonu
        if st.button("ğŸ§¹ Ã–nbelleÄŸi Temizle"):
            try:
                st.cache_data.clear()
                st.cache_resource.clear()
                st.success("Ã–nbellek temizlendi!")
            except:
                st.error("Ã–nbellek temizlenirken hata oluÅŸtu.")
            st.rerun()
    
    # Belgeler ve vektÃ¶r veritabanÄ±
    with st.spinner("Sistem hazÄ±rlanÄ±yor..."):
        try:
            if use_test_data:
                documents = create_test_documents()
                st.info("Test belgeleri kullanÄ±lÄ±yor")
            else:
                documents = load_documents_from_folder("data")
                st.success("GerÃ§ek belgeler yÃ¼klendi")
                
            if not documents:
                st.error("HiÃ§ belge bulunamadÄ±!")
                st.stop()
            
            # Ä°ÅŸlenen belgeleri gÃ¶ster
            st.subheader("YÃ¼klenen Belgeler")
            for doc in documents:
                with st.expander(f"{doc.metadata.get('source', 'Bilinmeyen')}"):
                    st.text(doc.page_content[:500] + ("..." if len(doc.page_content) > 500 else ""))
            
            vector_db = create_vector_db(documents)
            if not vector_db:
                st.error("VektÃ¶r veritabanÄ± oluÅŸturulamadÄ±!")
                st.stop()
            
            chat_chain = create_chat_chain(vector_db)
            if not chat_chain:
                st.error("Sohbet sistemi oluÅŸturulamadÄ±!")
                st.stop()
                
        except Exception as e:
            logging.error(f"Sistem hazÄ±rlama hatasÄ±: {str(e)}")
            st.error(f"Sistem hazÄ±rlanÄ±rken bir hata oluÅŸtu: {str(e)}")
            st.stop()
    
    # Sohbet arayÃ¼zÃ¼ baÅŸlÄ±ÄŸÄ±
    st.subheader("ğŸ’¬ Sorunuzu Sorun")
    st.write("Sistemde yÃ¼klenen belgeler hakkÄ±nda soru sorabilirsiniz. Ã–rneÄŸin: 'Nisan ayÄ± giderleri nedir?' veya 'Son yapÄ±lan etkinliÄŸin maliyeti nedir?'")
    
    # Sohbet geÃ§miÅŸini gÃ¶rÃ¼ntÃ¼le
    for i in range(0, len(st.session_state.chat_history), 2):
        if i < len(st.session_state.chat_history):
            with st.chat_message("user"):
                st.markdown(st.session_state.chat_history[i][1])
        
        if i+1 < len(st.session_state.chat_history):
            with st.chat_message("assistant"):
                st.markdown(st.session_state.chat_history[i+1][1])
    
    # KullanÄ±cÄ± giriÅŸi
    user_input = st.chat_input("Sorunuzu yazÄ±nÄ±z...")
    
    if user_input:
        with st.chat_message("user"):
            st.markdown(user_input)
        
        st.session_state.chat_history.append(("user", user_input))
        
        try:
            # Sohbet geÃ§miÅŸini uygun formata dÃ¶nÃ¼ÅŸtÃ¼r
            chat_formatted = []
            for i in range(0, len(st.session_state.chat_history)-1, 2):
                if i+1 < len(st.session_state.chat_history):
                    chat_formatted.append((st.session_state.chat_history[i][1], 
                                        st.session_state.chat_history[i+1][1]))
            
            # YanÄ±t oluÅŸtur
            with st.spinner("DÃ¼ÅŸÃ¼nÃ¼yor..."):
                response = chat_chain({
                    "question": user_input,
                    "chat_history": chat_formatted
                })
            
            # YanÄ±tÄ± gÃ¶ster
            with st.chat_message("assistant"):
                st.markdown(response["answer"])
                
                # KullanÄ±lan kaynaklarÄ± gÃ¶ster
                with st.expander("KullanÄ±lan Kaynaklar", expanded=False):
                    for i, doc in enumerate(response["source_documents"]):
                        source = doc.metadata.get("source", "Bilinmeyen")
                        st.markdown(f"**Kaynak {i+1}:** {source}")
                        st.markdown(f"```\n{doc.page_content[:300]}...\n```")
            
            # YanÄ±tÄ± geÃ§miÅŸe ekle
            st.session_state.chat_history.append(("assistant", response["answer"]))
            
        except Exception as e:
            logging.error(f"YanÄ±t hatasÄ±: {str(e)}")
            with st.chat_message("assistant"):
                st.error("ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸturulurken bir hata oluÅŸtu.")
            st.session_state.chat_history.append(("assistant", "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu."))

# ---------------------------------------
# 10. Uygulama BaÅŸlatÄ±lÄ±yor
# ---------------------------------------
if __name__ == "__main__":
    main()